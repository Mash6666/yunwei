from typing import Dict, List, Optional, Any
from datetime import datetime
import logging
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from config import Config
from states import OpsAssistantState, MetricValue, SystemAlert, AlertLevel

logger = logging.getLogger(__name__)

class SystemAnalyzer:
    """ç³»ç»Ÿæ™ºèƒ½åˆ†æå™¨"""

    def __init__(self):
        llm_config = Config.get_llm_config()
        self.llm = ChatOpenAI(**llm_config)
        self.system_prompt = self._build_system_prompt()

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Linuxç³»ç»Ÿè¿ç»´ä¸“å®¶å’Œæ™ºèƒ½è¿ç»´åŠ©æ‰‹ã€‚ä½ çš„ä¸»è¦èŒè´£æ˜¯ï¼š

1. **ç³»ç»Ÿç›‘æ§åˆ†æ**ï¼š
   - åˆ†æCPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œç­‰ç³»ç»ŸæŒ‡æ ‡
   - è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œå¼‚å¸¸æƒ…å†µ
   - è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶æ€

2. **é—®é¢˜è¯Šæ–­**ï¼š
   - åŸºäºç›‘æ§æ•°æ®è¯Šæ–­ç³»ç»Ÿé—®é¢˜
   - åˆ†æé—®é¢˜æ ¹æœ¬åŸå› 
   - è¯„ä¼°é—®é¢˜å½±å“ç¨‹åº¦

3. **è§£å†³æ–¹æ¡ˆå»ºè®®**ï¼š
   - æä¾›å…·ä½“çš„ä¿®å¤æ“ä½œæ­¥éª¤
   - å»ºè®®é¢„é˜²æ€§æªæ–½
   - è¯„ä¼°æ“ä½œé£é™©

4. **è‡ªåŠ¨åŒ–å†³ç­–**ï¼š
   - åˆ¤æ–­æ˜¯å¦éœ€è¦è‡ªåŠ¨ä¿®å¤
   - ç¡®å®šä¿®å¤çš„ä¼˜å…ˆçº§
   - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’

**åˆ†æåŸåˆ™**ï¼š
- ä¼˜å…ˆè€ƒè™‘ç³»ç»Ÿç¨³å®šæ€§å’Œæ•°æ®å®‰å…¨
- éµå¾ªæœ€å°å¹²é¢„åŸåˆ™
- æä¾›å¯æ“ä½œçš„å…·ä½“å»ºè®®
- è€ƒè™‘æ“ä½œçš„å›æ»šæ–¹æ¡ˆ

**å“åº”æ ¼å¼**ï¼š
- ä½¿ç”¨ç®€æ´æ˜äº†çš„æŠ€æœ¯è¯­è¨€
- æä¾›å…·ä½“çš„å‘½ä»¤å’Œæ“ä½œæ­¥éª¤
- åŒ…å«é£é™©è¯„ä¼°å’Œæ³¨æ„äº‹é¡¹
- æŒ‰ä¼˜å…ˆçº§æ’åˆ—å»ºè®®æ“ä½œ

è¯·åŸºäºæä¾›çš„ç›‘æ§æ•°æ®å’Œç³»ç»Ÿä¿¡æ¯ï¼Œè¿›è¡Œä¸“ä¸šçš„åˆ†æå’Œå»ºè®®ã€‚"""

    def analyze_metrics(self, metrics: List[MetricValue], alerts: List[SystemAlert]) -> Dict[str, Any]:
        """åˆ†æç›‘æ§æŒ‡æ ‡å’Œå‘Šè­¦"""
        try:
            # æ„å»ºåˆ†æä¸Šä¸‹æ–‡
            context = self._build_analysis_context(metrics, alerts)

            # ç”Ÿæˆåˆ†ææç¤º
            analysis_prompt = self._build_analysis_prompt(context)

            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            messages = [
                SystemMessage(content=self.system_prompt),
                HumanMessage(content=analysis_prompt)
            ]

            response = self.llm.invoke(messages)
            analysis_text = response.content

            # è§£æåˆ†æç»“æœ
            parsed_result = self._parse_analysis_result(analysis_text)

            return {
                "raw_analysis": analysis_text,
                "detected_issues": parsed_result.get("issues", []),
                "recommended_actions": parsed_result.get("actions", []),
                "risk_assessment": parsed_result.get("risks", []),
                "urgency_level": parsed_result.get("urgency", "medium"),
                "auto_fixable": parsed_result.get("auto_fixable", False)
            }

        except Exception as e:
            logger.error(f"åˆ†æç›‘æ§æŒ‡æ ‡å¤±è´¥: {e}")
            return {
                "raw_analysis": f"åˆ†æå¤±è´¥: {str(e)}",
                "detected_issues": ["åˆ†ææœåŠ¡å¼‚å¸¸"],
                "recommended_actions": ["è¯·æ£€æŸ¥åˆ†æå™¨é…ç½®"],
                "risk_assessment": ["ç³»ç»Ÿåˆ†æä¸å¯ç”¨"],
                "urgency_level": "high",
                "auto_fixable": False
            }

    def _build_analysis_context(self, metrics: List[MetricValue], alerts: List[SystemAlert]) -> Dict[str, Any]:
        """æ„å»ºåˆ†æä¸Šä¸‹æ–‡"""
        # æŒ‰ç±»å‹åˆ†ç»„æŒ‡æ ‡
        cpu_metrics = [m for m in metrics if 'cpu' in m.name.lower()]
        memory_metrics = [m for m in metrics if 'memory' in m.name.lower()]
        disk_metrics = [m for m in metrics if 'disk' in m.name.lower()]
        network_metrics = [m for m in metrics if 'network' in m.name.lower() or 'tcp' in m.name.lower()]
        system_metrics = [m for m in metrics if 'load' in m.name.lower()]

        # ç»Ÿè®¡å‘Šè­¦çº§åˆ«
        critical_alerts = [a for a in alerts if a.level == AlertLevel.CRITICAL]
        warning_alerts = [a for a in alerts if a.level == AlertLevel.WARNING]

        context = {
            "timestamp": datetime.now().isoformat(),
            "metrics_summary": {
                "total_metrics": len(metrics),
                "cpu_metrics": len(cpu_metrics),
                "memory_metrics": len(memory_metrics),
                "disk_metrics": len(disk_metrics),
                "network_metrics": len(network_metrics),
                "system_metrics": len(system_metrics)
            },
            "alerts_summary": {
                "total_alerts": len(alerts),
                "critical_alerts": len(critical_alerts),
                "warning_alerts": len(warning_alerts)
            },
            "detailed_metrics": {
                "cpu": self._format_metrics_for_analysis(cpu_metrics),
                "memory": self._format_metrics_for_analysis(memory_metrics),
                "disk": self._format_metrics_for_analysis(disk_metrics),
                "network": self._format_metrics_for_analysis(network_metrics),
                "system": self._format_metrics_for_analysis(system_metrics)
            },
            "active_alerts": [
                {
                    "metric": alert.metric_name,
                    "level": alert.level.value,
                    "message": alert.message,
                    "value": alert.value,
                    "threshold": alert.threshold,
                    "suggested_actions": alert.suggested_actions
                }
                for alert in alerts
            ]
        }

        return context

    def _format_metrics_for_analysis(self, metrics: List[MetricValue]) -> List[Dict[str, Any]]:
        """æ ¼å¼åŒ–æŒ‡æ ‡ç”¨äºåˆ†æ"""
        formatted = []
        for metric in metrics:
            formatted.append({
                "name": metric.name,
                "value": metric.value,
                "unit": metric.unit,
                "threshold": metric.threshold,
                "status": metric.status.value,
                "timestamp": metric.timestamp.isoformat()
            })
        return formatted

    def _build_analysis_prompt(self, context: Dict[str, Any]) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt = f"""è¯·åˆ†æä»¥ä¸‹Linuxç³»ç»Ÿç›‘æ§æ•°æ®ï¼Œå¹¶æä¾›ä¸“ä¸šçš„è¿ç»´å»ºè®®ï¼š

## ç³»ç»Ÿç›‘æ§æ¦‚è§ˆ
- åˆ†ææ—¶é—´: {context['timestamp']}
- æ€»æŒ‡æ ‡æ•°: {context['metrics_summary']['total_metrics']}
- å‘Šè­¦æ•°é‡: {context['alerts_summary']['total_alerts']} (ä¸¥é‡: {context['alerts_summary']['critical_alerts']}, è­¦å‘Š: {context['alerts_summary']['warning_alerts']})

## å…³é”®æŒ‡æ ‡æ•°æ®

### CPUæŒ‡æ ‡
{self._format_metric_group(context['detailed_metrics']['cpu'])}

### å†…å­˜æŒ‡æ ‡
{self._format_metric_group(context['detailed_metrics']['memory'])}

### ç£ç›˜æŒ‡æ ‡
{self._format_metric_group(context['detailed_metrics']['disk'])}

### ç½‘ç»œæŒ‡æ ‡
{self._format_metric_group(context['detailed_metrics']['network'])}

### ç³»ç»ŸæŒ‡æ ‡
{self._format_metric_group(context['detailed_metrics']['system'])}

## æ´»è·ƒå‘Šè­¦
{self._format_alerts(context['active_alerts'])}

## é…ç½®çš„é˜ˆå€¼
- CPUä½¿ç”¨ç‡é˜ˆå€¼: {Config.THRESHOLDS['cpu_usage']}%
- å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼: {Config.THRESHOLDS['memory_usage']}%
- ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼: {Config.THRESHOLDS['disk_usage']}%
- ç³»ç»Ÿè´Ÿè½½é˜ˆå€¼: {Config.THRESHOLDS['load_average']}

è¯·åŸºäºä»¥ä¸Šæ•°æ®æä¾›è¯¦ç»†çš„ç³»ç»Ÿåˆ†æå’Œå¯æ‰§è¡Œçš„ä¿®å¤æ–¹æ¡ˆï¼š
1. ç³»ç»ŸçŠ¶æ€æ€»ä½“è¯„ä¼°
2. æ£€æµ‹åˆ°çš„å…·ä½“é—®é¢˜åŠæ ¹å› åˆ†æ
3. å¯æ‰§è¡Œçš„ä¿®å¤æ–¹æ¡ˆï¼ˆåŒ…å«å…·ä½“çš„Shellå‘½ä»¤ï¼‰
4. æ“ä½œé£é™©è¯„ä¼°å’Œä¼˜å…ˆçº§
5. æ˜¯å¦å»ºè®®è‡ªåŠ¨ä¿®å¤
6. ä¿®å¤åéœ€è¦è¿›ä¸€æ­¥åˆ†æçš„å†…å®¹

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼å›å¤ï¼š
{{
    "overall_status": "healthy|warning|critical|unknown",
    "issues": ["é—®é¢˜1æè¿°", "é—®é¢˜2æè¿°"],
    "root_causes": ["æ ¹å› 1", "æ ¹å› 2"],
    "fix_plans": [
        {{
            "id": "plan_1",
            "issue": "é—®é¢˜æè¿°",
            "description": "è¯¦ç»†é—®é¢˜æè¿°å’Œå½±å“èŒƒå›´",
            "priority": "high|medium|low",
            "commands": [
                {{
                    "step": 1,
                    "description": "æ‰§è¡Œæ­¥éª¤æè¿°",
                    "command": "å…·ä½“çš„Shellå‘½ä»¤",
                    "expected_output": "é¢„æœŸè¾“å‡º",
                    "timeout": 30
                }},
                {{
                    "step": 2,
                    "description": "éªŒè¯æ­¥éª¤æè¿°",
                    "command": "éªŒè¯å‘½ä»¤",
                    "expected_output": "é¢„æœŸéªŒè¯ç»“æœ",
                    "timeout": 15
                }}
            ],
            "risk_level": "low|medium|high|critical",
            "estimated_time": "é¢„ä¼°æ‰§è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰",
            "preconditions": ["å‰ç½®æ¡ä»¶1", "å‰ç½®æ¡ä»¶2"],
            "rollback_commands": [
                {{
                    "step": 1,
                    "description": "å›æ»šæ­¥éª¤æè¿°",
                    "command": "å›æ»šå‘½ä»¤",
                    "timeout": 30
                }}
            ],
            "verification_commands": [
                {{
                    "step": 1,
                    "description": "éªŒè¯ä¿®å¤æ•ˆæœ",
                    "command": "éªŒè¯å‘½ä»¤",
                    "expected_output": "é¢„æœŸç»“æœ",
                    "timeout": 15
                }}
            ]
        }}
    ],
    "recommendations": ["é¢„é˜²æ€§å»ºè®®1", "é¢„é˜²æ€§å»ºè®®2"],
    "urgency": "low|medium|high|critical",
    "auto_fixable": true|false,
    "next_analysis": "ä¿®å¤åéœ€è¦è¿›ä¸€æ­¥åˆ†æçš„å†…å®¹",
    "impact_assessment": {{
        "affected_services": ["å—å½±å“çš„æœåŠ¡"],
        "potential_downtime": "é¢„ä¼°åœæœºæ—¶é—´",
        "data_risk": "æ•°æ®é£é™©ç­‰çº§"
    }}
}}

é‡è¦è¦æ±‚ï¼š
- commandså­—æ®µå¿…é¡»æä¾›å…·ä½“å¯æ‰§è¡Œçš„Shellå‘½ä»¤
- æ¯ä¸ªä¿®å¤è®¡åˆ’éƒ½åº”åŒ…å«å®Œæ•´çš„æ‰§è¡Œã€éªŒè¯å’Œå›æ»šæ–¹æ¡ˆ
- é£é™©è¯„ä¼°å¿…é¡»è€ƒè™‘ç³»ç»Ÿç¨³å®šæ€§å’Œæ•°æ®å®‰å…¨
- é¢„ä¼°æ—¶é—´åº”è¯¥åŒ…æ‹¬æ‰§è¡Œå’ŒéªŒè¯æ—¶é—´
- å›æ»šæ–¹æ¡ˆå¿…é¡»å®Œæ•´ä¸”å¯æ‰§è¡Œ
"""

        return prompt

    def _format_metric_group(self, metrics: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æŒ‡æ ‡ç»„"""
        if not metrics:
            return "æ— æ•°æ®"

        lines = []
        for metric in metrics:
            status_indicator = "âš ï¸" if metric['status'] == 'warning' else "âŒ" if metric['status'] == 'critical' else "âœ…"
            threshold_info = f" (é˜ˆå€¼: {metric['threshold']})" if metric['threshold'] else ""
            lines.append(f"{status_indicator} {metric['name']}: {metric['value']}{metric['unit']}{threshold_info}")

        return "\n".join(lines)

    def _format_alerts(self, alerts: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å‘Šè­¦ä¿¡æ¯"""
        if not alerts:
            return "æ— æ´»è·ƒå‘Šè­¦"

        lines = []
        for alert in alerts:
            level_indicator = "ğŸ”´" if alert['level'] == 'critical' else "ğŸŸ¡"
            lines.append(f"{level_indicator} {alert['metric']}: {alert['message']}")
            lines.append(f"   å½“å‰å€¼: {alert['value']}, é˜ˆå€¼: {alert['threshold']}")
            if alert['suggested_actions']:
                lines.append(f"   å»ºè®®æ“ä½œ: {', '.join(alert['suggested_actions'])}")
            lines.append("")

        return "\n".join(lines)

    def _parse_analysis_result(self, analysis_text: str) -> Dict[str, Any]:
        """è§£æLLMåˆ†æç»“æœ"""
        try:
            import json
            import re

            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', analysis_text)
            if json_match:
                json_str = json_match.group()
                parsed = json.loads(json_str)
                return parsed

            # å¦‚æœæ— æ³•è§£æJSONï¼Œè¿”å›åŸºæœ¬ç»“æ„
            return {
                "overall_status": "unknown",
                "issues": ["åˆ†æç»“æœè§£æå¤±è´¥"],
                "actions": ["è¯·æ‰‹åŠ¨æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"],
                "risks": ["è‡ªåŠ¨åˆ†æä¸å¯ç”¨"],
                "urgency": "medium",
                "auto_fixable": False
            }

        except Exception as e:
            logger.error(f"è§£æåˆ†æç»“æœå¤±è´¥: {e}")
            return {
                "overall_status": "unknown",
                "issues": ["åˆ†æç»“æœè§£æå¼‚å¸¸"],
                "actions": ["è¯·æŸ¥çœ‹åŸå§‹åˆ†æç»“æœ"],
                "risks": ["è‡ªåŠ¨åŒ–åˆ†ææš‚æ—¶ä¸å¯ç”¨"],
                "urgency": "medium",
                "auto_fixable": False
            }

    def generate_execution_plan(self, analysis_result: Dict[str, Any]) -> List[str]:
        """åŸºäºåˆ†æç»“æœç”Ÿæˆæ‰§è¡Œè®¡åˆ’"""
        execution_plan = []

        if not analysis_result.get("actions"):
            return execution_plan

        # æ ¹æ®ç´§æ€¥ç¨‹åº¦å’Œé£é™©æ’åºæ“ä½œ
        actions = analysis_result["actions"]
        urgency = analysis_result.get("urgency", "medium")
        auto_fixable = analysis_result.get("auto_fixable", False)

        # åªæœ‰åœ¨å»ºè®®è‡ªåŠ¨ä¿®å¤æ—¶æ‰ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        if auto_fixable:
            for action in actions:
                # å°†è‡ªç„¶è¯­è¨€å»ºè®®è½¬æ¢ä¸ºå…·ä½“å‘½ä»¤
                command = self._convert_action_to_command(action)
                if command:
                    execution_plan.append(command)

        return execution_plan

    def _convert_action_to_command(self, action: str) -> Optional[str]:
        """å°†æ“ä½œå»ºè®®è½¬æ¢ä¸ºå…·ä½“å‘½ä»¤"""
        action_lower = action.lower()

        # CPUç›¸å…³æ“ä½œ
        if "cpu" in action_lower and ("è¿›ç¨‹" in action_lower or "process" in action_lower):
            return "ps aux --sort=-%cpu | head -10"

        # å†…å­˜ç›¸å…³æ“ä½œ
        if "å†…å­˜" in action_lower and ("ç¼“å­˜" in action_lower or "cache" in action_lower):
            return "sync && echo 3 > /proc/sys/vm/drop_caches"

        # ç£ç›˜ç›¸å…³æ“ä½œ
        if "ç£ç›˜" in action_lower and ("æ¸…ç†" in action_lower or "clean" in action_lower):
            return "find /tmp -type f -atime +7 -delete"

        # ä¸´æ—¶æ–‡ä»¶æ¸…ç†
        if "ä¸´æ—¶æ–‡ä»¶" in action_lower or "temp" in action_lower:
            return "find /tmp -type f -size +100M -exec ls -lh {} \\;"

        # ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
        if "ç³»ç»Ÿ" in action_lower and ("çŠ¶æ€" in action_lower or "status" in action_lower):
            return "top -bn1 | head -20"

        # ç½‘ç»œè¿æ¥æ£€æŸ¥
        if "ç½‘ç»œ" in action_lower and ("è¿æ¥" in action_lower or "connection" in action_lower):
            return "netstat -an | grep ESTABLISHED | wc -l"

        # å¦‚æœæ— æ³•è¯†åˆ«ï¼Œè¿”å›ç³»ç»Ÿä¿¡æ¯å‘½ä»¤
        if "æ£€æŸ¥" in action_lower or "check" in action_lower:
            return "uptime && free -h && df -h"

        return None

    def get_quick_assessment(self, metrics: List[MetricValue]) -> str:
        """å¿«é€Ÿç³»ç»Ÿè¯„ä¼°"""
        critical_count = sum(1 for m in metrics if m.status == AlertLevel.CRITICAL)
        warning_count = sum(1 for m in metrics if m.status == AlertLevel.WARNING)

        if critical_count > 0:
            return f"ç³»ç»ŸçŠ¶æ€ï¼šä¸¥é‡å¼‚å¸¸ ({critical_count}ä¸ªä¸¥é‡å‘Šè­¦, {warning_count}ä¸ªè­¦å‘Š)"
        elif warning_count > 0:
            return f"ç³»ç»ŸçŠ¶æ€ï¼šè­¦å‘Š ({warning_count}ä¸ªè­¦å‘Š)"
        else:
            return "ç³»ç»ŸçŠ¶æ€ï¼šå¥åº·"

    def should_trigger_auto_fix(self, analysis_result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘è‡ªåŠ¨ä¿®å¤"""
        # åŸºäºå¤šä¸ªå› ç´ åˆ¤æ–­
        urgency = analysis_result.get("urgency", "low")
        auto_fixable = analysis_result.get("auto_fixable", False)
        critical_issues = len([issue for issue in analysis_result.get("issues", [])
                             if "ä¸¥é‡" in issue or "critical" in issue.lower()])

        # åªæœ‰åœ¨ç´§æ€¥ç¨‹åº¦é«˜ä¸”å¯è‡ªåŠ¨ä¿®å¤æ—¶æ‰è§¦å‘
        return (urgency in ["high", "critical"] and
                auto_fixable and
                critical_issues > 0)

    def create_fix_plan_from_analysis(self, analysis_result: Dict[str, Any]) -> List[str]:
        """ä»åˆ†æç»“æœåˆ›å»ºä¿®å¤è®¡åˆ’"""
        execution_plan = []

        # å¦‚æœæœ‰ä¿®å¤è®¡åˆ’ï¼Œä¼˜å…ˆä½¿ç”¨ä¿®å¤è®¡åˆ’
        if "fix_plans" in analysis_result and analysis_result["fix_plans"]:
            fix_plans = analysis_result["fix_plans"]
            auto_fixable = analysis_result.get("auto_fixable", False)

            # æŒ‰ä¼˜å…ˆçº§æ’åºä¿®å¤è®¡åˆ’
            priority_order = {"high": 0, "critical": 0, "medium": 1, "low": 2}
            sorted_plans = sorted(fix_plans, key=lambda x: (
                priority_order.get(x.get("priority", "medium"), 3),
                x.get("risk_level", "low")
            ))

            # å¦‚æœå»ºè®®è‡ªåŠ¨ä¿®å¤ï¼Œè½¬æ¢ä¸ºæ‰§è¡Œè®¡åˆ’
            if auto_fixable:
                for plan in sorted_plans:
                    for command in plan.get("commands", []):
                        execution_plan.append(command["command"])
            else:
                # å¦‚æœä¸è‡ªåŠ¨ä¿®å¤ï¼Œæ·»åŠ åˆ°è®¡åˆ’ä¸­ç­‰å¾…äººå·¥ç¡®è®¤
                for plan in sorted_plans:
                    plan_id = plan.get("id", f"plan_{len(execution_plan)}")
                    execution_plan.append(f"ä¿®å¤è®¡åˆ’: {plan.get('description', plan_id)}")

        # å¦‚æœæ²¡æœ‰ä¿®å¤è®¡åˆ’ä½†æœ‰ç®€å•æ“ä½œï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
        elif analysis_result.get("actions"):
            actions = analysis_result["actions"]
            for action in actions:
                command = self._convert_action_to_command(action)
                if command:
                    execution_plan.append(command)

        return execution_plan